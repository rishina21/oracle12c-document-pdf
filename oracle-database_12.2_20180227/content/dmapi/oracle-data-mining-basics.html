<!DOCTYPE html
  SYSTEM "about:legacy-compat">

<!-- saved from url=(0023)https://docs.oracle.com -->

<html xml:lang="en-us" lang="en-us">
   <head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
      <meta name="viewport" content="width=device-width, initial-scale=1">
      <meta http-equiv="X-UA-Compatible" content="IE=edge">
      <meta name="abstract" content="Understand the basic concepts of Oracle Data Mining.">
      <meta name="description" content="Understand the basic concepts of Oracle Data Mining.">
      <title>Oracle Data Mining Basics</title>
      <meta property="og:site_name" content="Oracle Help Center">
      <meta property="og:title" content="API Guide">
      <meta property="og:description" content="Understand the basic concepts of Oracle Data Mining.">
      <link rel="stylesheet" href="/sp_common/book-template/ohc-book-template/css/book.css">
      <link rel="shortcut icon" href="/sp_common/book-template/ohc-common/img/favicon.ico">
      <meta name="application-name" content="API Guide">
      <meta name="generator" content="DITA Open Toolkit version 1.8.5 (Mode = doc)">
      <meta name="plugin" content="SP_docbuilder HTML plugin release 17.8.1">
      <link rel="alternate" href="data-mining-api-guide.pdf" title="PDF File" type="application/pdf">
      <meta name="robots" content="all">
      <link rel="schema.dcterms" href="http://purl.org/dc/terms/">
      <meta name="dcterms.created" content="2017-11-22T10:58:10-08:00">
      
      <meta name="dcterms.dateCopyrighted" content="2005, 2017">
      <meta name="dcterms.category" content="database">
      <meta name="dcterms.identifier" content="E85759-01">
      
      <meta name="dcterms.product" content="en/database/oracle/oracle-database/12.2">
      <meta name="dcterms.release" content="Release 12.2">
      <link rel="prev" href="introduction-to-oracle-data-mining.html" title="Previous" type="text/html">
      <link rel="next" href="mining-fuctions.html" title="Next" type="text/html">
      <script>
        document.write('<style type="text/css">');
        document.write('body > .noscript, body > .noscript ~ * { visibility: hidden; }');
        document.write('</style>');
     </script>
      <script data-main="/sp_common/book-template/ohc-book-template/js/book-config" src="/sp_common/book-template/requirejs/require.js"></script>
      <script>
            if (window.require === undefined) {
                document.write('<script data-main="sp_common/book-template/ohc-book-template/js/book-config" src="sp_common/book-template/requirejs/require.js"><\/script>');
                document.write('<link href="sp_common/book-template/ohc-book-template/css/book.css" rel="stylesheet"/>');
            }
        </script>
      <script type="application/json" id="ssot-metadata">
            {
                "primary":
                {
                    "category":{
                      "short_name":"database",
                      "element_name":"Database",
                      "display_in_url":true
                    },
                    "suite":{
                      "short_name":"oracle",
                      "element_name":"Oracle",
                      "display_in_url":true
                    },
                    "product_group":{
                      "short_name":"not-applicable",
                      "element_name":"Not applicable",
                      "display_in_url":false
                    },
                    "product":{
                      "short_name":"oracle-database",
                      "element_name":"Oracle Database",
                      "display_in_url":true
                    },
                    "release":{
                      "short_name":"12.2",
                      "element_name":"Release 12.2",
                      "display_in_url":true
                    },
                    "platform":{
                      "short_name":"",
                      "element_name":"",
                      "display_in_url":false
                    },
                    "component":{
                      "short_name":"",
                      "element_name":"",
                      "display_in_url":false
                    }
                }
            }
            </script>
      
    <meta name="dcterms.title" content="Data Mining API Guide">
    <meta name="dcterms.isVersionOf" content="DMAPI">
  </head>
   <body>
      <div class="noscript alert alert-danger text-center" role="alert">
         <a href="introduction-to-oracle-data-mining.html" class="pull-left"><span class="glyphicon glyphicon-chevron-left" aria-hidden="true"></span>Previous</a>
         <a href="mining-fuctions.html" class="pull-right">Next<span class="glyphicon glyphicon-chevron-right" aria-hidden="true"></span></a>
         <span class="fa fa-exclamation-triangle" aria-hidden="true"></span> JavaScript must be enabled to correctly display this content
        
      </div>
      <article>
         <header>
            <ol class="breadcrumb" vocab="http://schema.org/" typeof="BreadcrumbList">
               <li property="itemListElement" typeof="ListItem"><a href="index.html" property="item" typeof="WebPage"><span property="name">API Guide</span></a></li>
               <li property="itemListElement" typeof="ListItem"><a href="oracle-data-mining.html" property="item" typeof="WebPage"><span property="name"> Introductions</span></a></li>
               <li class="active" property="itemListElement" typeof="ListItem">Oracle Data Mining Basics </li>
            </ol>
            <a id="GUID-2116E665-721E-4EBA-AFE1-A30D6E8078C6" name="GUID-2116E665-721E-4EBA-AFE1-A30D6E8078C6"></a>
            
            <h2 id="DMAPI-GUID-2116E665-721E-4EBA-AFE1-A30D6E8078C6" class="sect2"><span class="enumeration_chapter">2 </span>Oracle Data Mining Basics 
            </h2>
         </header>
         <div class="ind">
            <div>
               <p>Understand the basic concepts of Oracle Data Mining.</p>
               <p><a id="d6547e18" class="indexterm-anchor"></a></p>
               <ul style="list-style-type: disc;">
                  <li>
                     <p><a href="oracle-data-mining-basics.html#GUID-2E33469E-D6D2-4B31-B62D-3C2E2F88340B" title="Introduces the concept of data mining functions.">Mining Functions</a></p>
                  </li>
                  <li>
                     <p><a href="oracle-data-mining-basics.html#GUID-BFA7FAAE-F5CB-4A42-886A-47B6D502B492" title="Learn about unsupervised algorithms that Oracle Data Mining supports.">Algorithms</a></p>
                  </li>
                  <li>
                     <p><a href="oracle-data-mining-basics.html#GUID-1F28AA79-0508-40C4-BB62-A7A7EAFE5E2F" title="Prepare and transform unstructured text data for data mining.">Data Preparation</a></p>
                  </li>
                  <li>
                     <p><a href="oracle-data-mining-basics.html#GUID-21677973-2248-4119-A560-24D7F2FD7EAD" title="All Oracle Data Mining scoring routines support parallel execution for scoring large data sets.In Oracle Data Mining, scoring is performed by SQL language functions. Understand the different ways involved in SQL function scoring.">In-Database Scoring</a></p>
                  </li>
               </ul>
            </div><a id="DMCON030"></a><div class="props_rev_3"><a id="GUID-2E33469E-D6D2-4B31-B62D-3C2E2F88340B" name="GUID-2E33469E-D6D2-4B31-B62D-3C2E2F88340B"></a><h3 id="DMAPI-GUID-2E33469E-D6D2-4B31-B62D-3C2E2F88340B" class="sect3"><span class="enumeration_section">2.1 </span>Mining Functions
               </h3>
               <div>
                  <p>Introduces the concept of data mining functions.</p>
                  <p>A basic understanding of data <a id="d6547e77" class="indexterm-anchor"></a>mining functions and algorithms is required for using Oracle Data Mining.
                  </p>
                  <p>Each data mining <strong class="term">function</strong> specifies a class of problems that can be modeled and solved. Data mining functions fall generally into two categories: <strong class="term">supervised</strong> and <strong class="term">unsupervised</strong>. Notions of supervised and unsupervised learning are derived from the science of <a id="d6547e91" class="indexterm-anchor"></a>machine learning, which has been called a sub-area of <a id="d6547e94" class="indexterm-anchor"></a>artificial intelligence.
                  </p>
                  <p>Artificial intelligence refers to the implementation and study of systems that exhibit autonomous intelligence or behavior of their own. Machine learning deals with techniques that enable devices to learn from their own performance and modify their own functioning. Data mining applies machine learning concepts to data.</p>
               </div>
               <div>
                  <div class="relinfo">
                     <p><strong>Related Topics</strong></p>
                     <ul>
                        <li><a href="oracle-data-mining-basics.html#GUID-BFA7FAAE-F5CB-4A42-886A-47B6D502B492" title="Learn about unsupervised algorithms that Oracle Data Mining supports.">Algorithms</a></li>
                     </ul>
                  </div>
               </div><a id="DMCON128"></a><div class="props_rev_3"><a id="GUID-2BB02332-4824-4D04-BE04-4265C75BEAA9" name="GUID-2BB02332-4824-4D04-BE04-4265C75BEAA9"></a><h4 id="DMAPI-GUID-2BB02332-4824-4D04-BE04-4265C75BEAA9" class="sect4"><span class="enumeration_section">2.1.1 </span>Supervised Data Mining
                  </h4>
                  <div>
                     <p>Supervised <a id="d6547e127" class="indexterm-anchor"></a>learning is also known as <a id="d6547e130" class="indexterm-anchor"></a>directed learning. The learning process is directed by a previously known dependent attribute or <a id="d6547e133" class="indexterm-anchor"></a>target. Directed data mining attempts to explain the behavior of the target as a function of a set of independent attributes or predictors.
                     </p>
                     <p>Supervised learning generally results in <a id="d6547e138" class="indexterm-anchor"></a>predictive models. This is in contrast to unsupervised learning where the goal is pattern detection.
                     </p>
                     <p>The building of a supervised model involves <strong class="term">training</strong>, a process whereby the software analyzes many cases where the target value is already known. In the training process, the model "learns" the logic for making the prediction. For example, a model that seeks to identify the customers who are likely to respond to a promotion must be trained by analyzing the characteristics of many customers who are known to have responded or not responded to a promotion in the past.
                     </p>
                  </div><a id="DMCON129"></a><div class="props_rev_3"><a id="GUID-ED7D5FD4-E421-44DC-A790-A96274E649B2" name="GUID-ED7D5FD4-E421-44DC-A790-A96274E649B2"></a><h5 id="DMAPI-GUID-ED7D5FD4-E421-44DC-A790-A96274E649B2" class="sect5"><span class="enumeration_section">2.1.1.1 </span>Supervised Learning: Testing
                     </h5>
                     <div>
                        <p>Separate data sets are required for building (training) <a id="d6547e166" class="indexterm-anchor"></a>and testing some predictive models. The build data (training data) and test data must have the same column structure. Typically, one large table or view is split into two data sets: one for building the model, and the other for testing the model.
                        </p>
                        <p>The process of applying the model to test data helps to determine whether the model, built on one chosen sample, is generalizable to other data. In particular, it helps to avoid the phenomenon of <a id="d6547e173" class="indexterm-anchor"></a>overfitting, which can occur when the logic of the model fits the build data too well and therefore has little predictive power.
                        </p>
                     </div>
                  </div><a id="DMCON624"></a><a id="DMCON130"></a><div class="props_rev_3"><a id="GUID-99532F63-0417-45DC-908D-C5D7FCD083D9" name="GUID-99532F63-0417-45DC-908D-C5D7FCD083D9"></a><h5 id="DMAPI-GUID-99532F63-0417-45DC-908D-C5D7FCD083D9" class="sect5"><span class="enumeration_section">2.1.1.2 </span>Supervised Learning: Scoring
                     </h5>
                     <div>
                        <p><a id="d6547e196" class="indexterm-anchor"></a>Apply data, also <a id="d6547e201" class="indexterm-anchor"></a>called scoring data, is the actual <a id="d6547e206" class="indexterm-anchor"></a>population to which a model is applied. For example, you might build a model that identifies the characteristics of customers who frequently buy a certain product. To obtain a list of customers who shop at a certain store and are likely to buy a related product, you might apply the model to the customer data for that store. In this case, the store customer data is the scoring data.
                        </p>
                        <p>Most supervised learning can be applied to a population of interest. The principal supervised mining techniques, <strong class="term">Classification</strong> and <strong class="term">Regression</strong>, can both be used for scoring.
                        </p>
                        <p>Oracle Data Mining does not support the scoring operation for <strong class="term">Attribute Importance</strong>, another supervised function. Models of this type are built on a population of interest to obtain information about that population; they cannot be applied to separate data. An attribute importance model returns and ranks the attributes that are most important in predicting a target value. 
                        </p>
                        <p>Oracle Data Mining supports the supervised data mining functions described in<a id="d6547e226" class="indexterm-anchor"></a> the following table: 
                        </p>
                        <div class="tblformalwide" id="GUID-99532F63-0417-45DC-908D-C5D7FCD083D9__CIHDADDJ">
                           <p class="titleintable">Table 2-1 Oracle Data Mining Supervised Functions </p>
                           <table cellpadding="4" cellspacing="0" class="FormalWide" title="Oracle Data Mining Supervised Functions " summary="This table describes the predictive mining functions." width="100%" frame="hsides" border="1" rules="rows">
                              <thead>
                                 <tr align="left" valign="top">
                                    <th align="left" valign="bottom" width="24%" id="d6547e240">Function</th>
                                    <th align="left" valign="bottom" width="37%" id="d6547e243">Description</th>
                                    <th align="left" valign="bottom" width="39%" id="d6547e246">Sample Problem</th>
                                 </tr>
                              </thead>
                              <tbody>
                                 <tr align="left" valign="top">
                                    <td align="left" valign="top" width="24%" id="d6547e251" headers="d6547e240 ">
                                       <p>Attribute Importance<a id="d6547e254" class="indexterm-anchor"></a></p>
                                    </td>
                                    <td align="left" valign="top" width="37%" headers="d6547e251 d6547e243 ">
                                       <p>Identifies the attributes that are most important in predicting a target attribute</p>
                                    </td>
                                    <td align="left" valign="top" width="39%" headers="d6547e251 d6547e246 ">
                                       <p>Given customer response to an affinity card program, find the most significant predictors</p>
                                    </td>
                                 </tr>
                                 <tr align="left" valign="top">
                                    <td align="left" valign="top" width="24%" id="d6547e263" headers="d6547e240 ">
                                       <p><a id="d6547e265" class="indexterm-anchor"></a><a id="d6547e267" class="indexterm-anchor"></a>Classification
                                       </p>
                                    </td>
                                    <td align="left" valign="top" width="37%" headers="d6547e263 d6547e243 ">
                                       <p>Assigns items to discrete classes and predicts the class to which an item belongs</p>
                                    </td>
                                    <td align="left" valign="top" width="39%" headers="d6547e263 d6547e246 ">
                                       <p>Given demographic data about a set of customers, predict customer response to an affinity card program</p>
                                    </td>
                                 </tr>
                                 <tr align="left" valign="top">
                                    <td align="left" valign="top" width="24%" id="d6547e279" headers="d6547e240 ">
                                       <p><a id="d6547e281" class="indexterm-anchor"></a><a id="d6547e283" class="indexterm-anchor"></a>Regression
                                       </p>
                                    </td>
                                    <td align="left" valign="top" width="37%" headers="d6547e279 d6547e243 ">
                                       <p>Approximates and forecasts continuous values</p>
                                    </td>
                                    <td align="left" valign="top" width="39%" headers="d6547e279 d6547e246 ">
                                       <p>Given demographic and purchasing data about a set of customers, predict customers' age</p>
                                    </td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                        <!-- class="inftblhruleinformal" -->
                     </div>
                  </div>
               </div><a id="DMCON131"></a><div class="props_rev_3"><a id="GUID-91F9B08B-B262-4726-A109-A90E68A062D0" name="GUID-91F9B08B-B262-4726-A109-A90E68A062D0"></a><h4 id="DMAPI-GUID-91F9B08B-B262-4726-A109-A90E68A062D0" class="sect4"><span class="enumeration_section">2.1.2 </span>Unsupervised Data Mining
                  </h4>
                  <div>
                     <p>Unsupervised <a id="d6547e319" class="indexterm-anchor"></a>learning is non-directed. There is no distinction between dependent and independent attributes. There is no previously-known result to guide the algorithm in building the model.
                     </p>
                     <p>Unsupervised learning can be used for <strong class="term">descriptive</strong> purposes. It can also be used to make predictions. 
                     </p>
                  </div><a id="DMCON135"></a><a id="DMCON132"></a><div class="props_rev_3"><a id="GUID-039F01D5-C94A-4571-9C08-3B9D8AB78629" name="GUID-039F01D5-C94A-4571-9C08-3B9D8AB78629"></a><h5 id="DMAPI-GUID-039F01D5-C94A-4571-9C08-3B9D8AB78629" class="sect5"><span class="enumeration_section">2.1.2.1 </span>Unsupervised Learning: Scoring
                     </h5>
                     <div>
                        <p>Introduces unsupervised learning, supported scoring operations, and unsupervised Oracle Data Mining functions.</p>
                        <p>Although unsupervised data mining does not <a id="d6547e360" class="indexterm-anchor"></a>specify a <a id="d6547e365" class="indexterm-anchor"></a>target, most unsupervised learning can be applied to a population of interest. For exa<a id="d6547e368" class="indexterm-anchor"></a>mple, <a id="d6547e373" class="indexterm-anchor"></a>clustering models use descriptive data mining techniques, but they can be applied to classify cases according to their cluster assignments. <a id="d6547e376" class="indexterm-anchor"></a><a id="d6547e378" class="indexterm-anchor"></a><strong class="term">Anomaly detection</strong>, <a id="d6547e386" class="indexterm-anchor"></a>although unsupervised, is typically used to predict whether a data point is typical among a set of cases.
                        </p>
                        <p>Oracle Data Mining supports the scoring operation for <a id="d6547e393" class="indexterm-anchor"></a><a id="d6547e395" class="indexterm-anchor"></a><strong class="term">Clustering</strong> and <strong class="term">Feature Extraction</strong>, both unsupervised mining functions. Oracle Data Mining does not support the <a id="d6547e403" class="indexterm-anchor"></a>scoring operation for <a id="d6547e406" class="indexterm-anchor"></a><strong class="term">Association Rules</strong>, another unsupervised function. Association models are built on a population of interest to obtain information about that population; they cannot be applied to separate data. An association model returns rules that explain how items or events are associated with each other. The association rules are returned with statistics that can be used to rank them according to their probability. 
                        </p>
                        <p>Oracle Data Mining supports the unsupervised functions described in the following table:</p>
                        <div class="tblformalwide" id="GUID-039F01D5-C94A-4571-9C08-3B9D8AB78629__CHDDDCEE">
                           <p class="titleintable">Table 2-2 Oracle Data Mining Unsupervised Functions</p>
                           <table cellpadding="4" cellspacing="0" class="FormalWide" title="Oracle Data Mining Unsupervised Functions" summary="This table describes the descriptive data mining functions." width="100%" frame="hsides" border="1" rules="rows">
                              <thead>
                                 <tr align="left" valign="top">
                                    <th align="left" valign="bottom" width="20%" id="d6547e424">Function</th>
                                    <th align="left" valign="bottom" width="36%" id="d6547e427">Description</th>
                                    <th align="left" valign="bottom" width="43%" id="d6547e430">Sample Problem</th>
                                 </tr>
                              </thead>
                              <tbody>
                                 <tr align="left" valign="top">
                                    <td align="left" valign="top" width="20%" id="d6547e435" headers="d6547e424 ">
                                       <p><a id="d6547e437" class="indexterm-anchor"></a><a id="d6547e439" class="indexterm-anchor"></a>Anomaly Detection
                                       </p>
                                    </td>
                                    <td align="left" valign="top" width="36%" headers="d6547e435 d6547e427 ">
                                       <p>Identifies items (outliers) that do not satisfy the characteristics of "normal" data</p>
                                    </td>
                                    <td align="left" valign="top" width="43%" headers="d6547e435 d6547e430 ">
                                       <p>Given demographic data about a set of customers, identify customer purchasing behavior that is significantly different from the norm</p>
                                    </td>
                                 </tr>
                                 <tr align="left" valign="top">
                                    <td align="left" valign="top" width="20%" id="d6547e451" headers="d6547e424 ">
                                       <p>Association<a id="d6547e454" class="indexterm-anchor"></a><a id="d6547e456" class="indexterm-anchor"></a> Rules
                                       </p>
                                    </td>
                                    <td align="left" valign="top" width="36%" headers="d6547e451 d6547e427 ">
                                       <p>Finds items that tend to co-occur in the data and specifies the rules that govern their co-occurrence</p>
                                    </td>
                                    <td align="left" valign="top" width="43%" headers="d6547e451 d6547e430 ">
                                       <p>Find the items that tend to be purchased together and specify their relationship</p>
                                    </td>
                                 </tr>
                                 <tr align="left" valign="top">
                                    <td align="left" valign="top" width="20%" id="d6547e468" headers="d6547e424 ">
                                       <p>Clustering<a id="d6547e471" class="indexterm-anchor"></a><a id="d6547e473" class="indexterm-anchor"></a></p>
                                    </td>
                                    <td align="left" valign="top" width="36%" headers="d6547e468 d6547e427 ">
                                       <p>Finds natural groupings in the data</p>
                                    </td>
                                    <td align="left" valign="top" width="43%" headers="d6547e468 d6547e430 ">
                                       <p>Segment demographic data into clusters and rank the probability that an individual belongs to a given cluster</p>
                                    </td>
                                 </tr>
                                 <tr align="left" valign="top">
                                    <td align="left" valign="top" width="20%" id="d6547e484" headers="d6547e424 ">
                                       <p>Feature Extraction<a id="d6547e487" class="indexterm-anchor"></a><a id="d6547e489" class="indexterm-anchor"></a></p>
                                    </td>
                                    <td align="left" valign="top" width="36%" headers="d6547e484 d6547e427 ">
                                       <p>Creates new <a id="d6547e496" class="indexterm-anchor"></a>attributes (features) using linear combinations of the original attributes
                                       </p>
                                    </td>
                                    <td align="left" valign="top" width="43%" headers="d6547e484 d6547e430 ">
                                       <p>Given demographic data about a set of customers, group the attributes into general characteristics of the customers</p>
                                    </td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                        <!-- class="inftblhruleinformal" -->
                     </div>
                     <div>
                        <div class="relinfo">
                           <p><strong>Related Topics</strong></p>
                           <ul>
                              <li><a href="mining-fuctions.html#GUID-3BC8FD92-9B6A-4612-A458-7E5FFDDC5EA7" title="Part II provides basic conceptual information about the mining functions that the Oracle Data Mining supports.">Mining Functions</a></li>
                              <li><a href="oracle-data-mining-basics.html#GUID-21677973-2248-4119-A560-24D7F2FD7EAD" title="All Oracle Data Mining scoring routines support parallel execution for scoring large data sets.In Oracle Data Mining, scoring is performed by SQL language functions. Understand the different ways involved in SQL function scoring.">In-Database Scoring</a></li>
                           </ul>
                        </div>
                     </div>
                  </div>
               </div>
            </div><a id="DMCON031"></a><div class="props_rev_3"><a id="GUID-BFA7FAAE-F5CB-4A42-886A-47B6D502B492" name="GUID-BFA7FAAE-F5CB-4A42-886A-47B6D502B492"></a><h3 id="DMAPI-GUID-BFA7FAAE-F5CB-4A42-886A-47B6D502B492" class="sect3"><span class="enumeration_section">2.2 </span>Algorithms
               </h3>
               <div>
                  <p>An <a id="d6547e538" class="indexterm-anchor"></a>algorithm is a mathematical procedure for solving a specific kind of problem. Oracle Data Mining supports at least one algorithm for each data mining function. For some functions, you can choose among several algorithms. For example, Oracle Data Mining supports four classification algorithms.
                  </p>
                  <p>Each data mining model is produced by a specific algorithm. Some data mining problems can best be solved by using more than one algorithm. This necessitates the development of more than one model. For example, you might first use a feature extraction model to create an optimized set of predictors, then a classification model to make a prediction on the results.</p>
               </div><a id="DMCON137"></a><a id="DMCON136"></a><div class="props_rev_3"><a id="GUID-208DD1B9-4B6E-4D51-A1C2-C58356DECE4E" name="GUID-208DD1B9-4B6E-4D51-A1C2-C58356DECE4E"></a><h4 id="DMAPI-GUID-208DD1B9-4B6E-4D51-A1C2-C58356DECE4E" class="sect4"><span class="enumeration_section">2.2.1 </span>Oracle Data Mining Supervised Algorithms
                  </h4>
                  <div>
                     <p>Oracle <a id="d6547e566" class="indexterm-anchor"></a>Data Mining supports the supervised data mining <a id="d6547e571" class="indexterm-anchor"></a>algorithms described in the following table. The algorithm abbreviations are used throughout this manual.
                     </p>
                     <div class="tblformalwide" id="GUID-208DD1B9-4B6E-4D51-A1C2-C58356DECE4E__BHCGGHBA">
                        <p class="titleintable">Table 2-3 Oracle Data Mining Algorithms for Supervised Functions</p>
                        <table cellpadding="4" cellspacing="0" class="FormalWide" title="Oracle Data Mining Algorithms for Supervised Functions" summary="Oracle Algorithms for Supervised Data Mining" width="100%" frame="hsides" border="1" rules="rows">
                           <thead>
                              <tr align="left" valign="top">
                                 <th align="left" valign="bottom" width="20%" id="d6547e587">Algorithm</th>
                                 <th align="left" valign="bottom" width="16%" id="d6547e590">Function</th>
                                 <th align="left" valign="bottom" width="64%" id="d6547e593">Description</th>
                              </tr>
                           </thead>
                           <tbody>
                              <tr align="left" valign="top">
                                 <td align="left" valign="top" width="20%" id="d6547e598" headers="d6547e587 ">
                                    <p><a id="d6547e600" class="indexterm-anchor"></a><a id="d6547e602" class="indexterm-anchor"></a>Decision Tree
                                    </p>
                                 </td>
                                 <td align="left" valign="top" width="16%" headers="d6547e598 d6547e590 ">
                                    <p><a id="d6547e609" class="indexterm-anchor"></a><a id="d6547e611" class="indexterm-anchor"></a>Classification
                                    </p>
                                 </td>
                                 <td align="left" valign="top" width="64%" headers="d6547e598 d6547e593 ">
                                    <p>Decision trees extract predictive information in the form of human-understandable rules. The rules are if-then-else expressions; they explain the decisions that lead to the prediction.</p>
                                 </td>
                              </tr>
                              <tr align="left" valign="top">
                                 <td align="left" valign="top" width="20%" id="d6547e620" headers="d6547e587 ">
                                    <p><a id="d6547e622" class="indexterm-anchor"></a><a id="d6547e624" class="indexterm-anchor"></a>Generalized Linear Models
                                    </p>
                                 </td>
                                 <td align="left" valign="top" width="16%" headers="d6547e620 d6547e590 ">
                                    <p>Classification and <a id="d6547e632" class="indexterm-anchor"></a><a id="d6547e634" class="indexterm-anchor"></a>Regression
                                    </p>
                                 </td>
                                 <td align="left" valign="top" width="64%" headers="d6547e620 d6547e593 ">
                                    <p>Generalized Linear Models (GLM) implement <a id="d6547e642" class="indexterm-anchor"></a>logistic regression for classification of binary targets and<a id="d6547e645" class="indexterm-anchor"></a> linear regression for continuous targets. GLM classification supports<a id="d6547e648" class="indexterm-anchor"></a> confidence bounds for prediction probabilities. GLM regression supports confidence bounds for predictions.
                                    </p>
                                 </td>
                              </tr>
                              <tr align="left" valign="top">
                                 <td align="left" valign="top" width="20%" id="d6547e652" headers="d6547e587 ">
                                    <p><a id="d6547e654" class="indexterm-anchor"></a><a id="d6547e656" class="indexterm-anchor"></a>Minimum Description Length
                                    </p>
                                 </td>
                                 <td align="left" valign="top" width="16%" headers="d6547e652 d6547e590 ">
                                    <p><a id="d6547e663" class="indexterm-anchor"></a><a id="d6547e665" class="indexterm-anchor"></a>Attribute Importance
                                    </p>
                                 </td>
                                 <td align="left" valign="top" width="64%" headers="d6547e652 d6547e593 ">
                                    <p>Minimum Description Length (MDL) is an information theoretic model selection principle. MDL assumes that the simplest, most compact representation of data is the best and most probable explanation of the data.</p>
                                 </td>
                              </tr>
                              <tr align="left" valign="top">
                                 <td align="left" valign="top" width="20%" id="d6547e674" headers="d6547e587 ">
                                    <p><a id="d6547e676" class="indexterm-anchor"></a><a id="d6547e678" class="indexterm-anchor"></a>Naive Bayes
                                    </p>
                                 </td>
                                 <td align="left" valign="top" width="16%" headers="d6547e674 d6547e590 ">
                                    <p>Classification</p>
                                 </td>
                                 <td align="left" valign="top" width="64%" headers="d6547e674 d6547e593 ">
                                    <p>Naive Bayes makes predictions using Bayes' Theorem, which derives the probability of a prediction from the underlying evidence, as observed in the data. </p>
                                 </td>
                              </tr>
                              <tr align="left" valign="top">
                                 <td align="left" valign="top" width="20%" id="d6547e690" headers="d6547e587 ">
                                    <p><a id="d6547e692" class="indexterm-anchor"></a><a id="d6547e694" class="indexterm-anchor"></a>Support Vector Machines 
                                    </p>
                                 </td>
                                 <td align="left" valign="top" width="16%" headers="d6547e690 d6547e590 ">
                                    <p>Classification and Regression</p>
                                 </td>
                                 <td align="left" valign="top" width="64%" headers="d6547e690 d6547e593 ">
                                    <p>Distinct versions of Support Vector Machines (SVM) use different kernel functions to handle different types of data sets. <a id="d6547e705" class="indexterm-anchor"></a><a id="d6547e709" class="indexterm-anchor"></a>Linear and Gaussian (nonlinear) kernels are supported.
                                    </p>
                                    <p>SVM <a id="d6547e716" class="indexterm-anchor"></a>classification attempts to separate the target classes with the widest possible margin.
                                    </p>
                                    <p>SVM <a id="d6547e723" class="indexterm-anchor"></a>regression tries to find a continuous function such that the maximum number of data points lie within an epsilon-wide tube around it. 
                                    </p>
                                 </td>
                              </tr>
                           </tbody>
                        </table>
                     </div>
                     <!-- class="inftblhruleinformal" -->
                  </div>
               </div><a id="DMCON139"></a><a id="DMCON138"></a><div class="props_rev_3"><a id="GUID-B232C37E-6B54-43C7-8498-1B9D63219A09" name="GUID-B232C37E-6B54-43C7-8498-1B9D63219A09"></a><h4 id="DMAPI-GUID-B232C37E-6B54-43C7-8498-1B9D63219A09" class="sect4"><span class="enumeration_section">2.2.2 </span>Oracle Data Mining Unsupervised Algorithms
                  </h4>
                  <div>
                     <p>Learn about unsupervised algorithms that Oracle Data Mining supports. </p>
                     <p>Oracle Data Mining <a id="d6547e751" class="indexterm-anchor"></a>supports the unsupervised data mining algorithms described in the following table. The algorithm abbreviations are used throughout this manual.
                     </p>
                     <div class="tblformalwide" id="GUID-B232C37E-6B54-43C7-8498-1B9D63219A09__BHCHAHIG">
                        <p class="titleintable">Table 2-4 Oracle Data Mining Algorithms for Unsupervised Functions</p>
                        <table cellpadding="4" cellspacing="0" class="FormalWide" title="Oracle Data Mining Algorithms for Unsupervised Functions" summary="Lists the unsupervised data mining algorithms supported by Oracle Data Mining." width="100%" frame="hsides" border="1" rules="rows">
                           <thead>
                              <tr align="left" valign="top">
                                 <th align="left" valign="bottom" width="20%" id="d6547e767">Algorithm</th>
                                 <th align="left" valign="bottom" width="18%" id="d6547e770">Function</th>
                                 <th align="left" valign="bottom" width="62%" id="d6547e773">Description</th>
                              </tr>
                           </thead>
                           <tbody>
                              <tr align="left" valign="top">
                                 <td align="left" valign="top" width="20%" id="d6547e778" headers="d6547e767 ">
                                    <p><a id="d6547e780" class="indexterm-anchor"></a><a id="d6547e782" class="indexterm-anchor"></a>Apriori
                                    </p>
                                 </td>
                                 <td align="left" valign="top" width="18%" headers="d6547e778 d6547e770 ">
                                    <p><a id="d6547e789" class="indexterm-anchor"></a><a id="d6547e791" class="indexterm-anchor"></a>Association
                                    </p>
                                 </td>
                                 <td align="left" valign="top" width="62%" headers="d6547e778 d6547e773 ">
                                    <p>Apriori performs market basket analysis by identifying co-occurring items (frequent itemsets) within a set. Apriori finds rules with support greater than a specified minimum <a id="d6547e799" class="indexterm-anchor"></a>support and <a id="d6547e804" class="indexterm-anchor"></a>confidence greater than a specified minimum confidence.
                                    </p>
                                 </td>
                              </tr>
                              <tr align="left" valign="top">
                                 <td align="left" valign="top" width="20%" id="d6547e810" headers="d6547e767 ">
                                    <p><a id="d6547e812" class="indexterm-anchor"></a><a id="d6547e814" class="indexterm-anchor"></a>Expectation Maximization
                                    </p>
                                 </td>
                                 <td align="left" valign="top" width="18%" headers="d6547e810 d6547e770 ">
                                    <p>Clustering</p>
                                 </td>
                                 <td align="left" valign="top" width="62%" headers="d6547e810 d6547e773 ">
                                    <p>Expectation Maximization (EM) is a density estimation algorithm that performs probabilistic clustering. In density estimation, the goal is to construct a density function that captures how a given population is distributed. The density estimate is based on observed data that represents a sample of the population.</p>
                                    <p>Oracle Data Mining supports probabilistic clustering and data frequency estimates and other applications of Expectation Maximization.</p>
                                 </td>
                              </tr>
                              <tr align="left" valign="top">
                                 <td align="left" valign="top" width="20%" id="d6547e828" headers="d6547e767 ">
                                    <p>Explicit Semantic Analysis<a id="d6547e831" class="indexterm-anchor"></a><a id="d6547e833" class="indexterm-anchor"></a></p>
                                 </td>
                                 <td align="left" valign="top" width="18%" headers="d6547e828 d6547e770 ">
                                    <p>Feature Extraction</p>
                                 </td>
                                 <td align="left" valign="top" width="62%" headers="d6547e828 d6547e773 ">
                                    <p>Explicit Semantic Analysis (ESA) uses existing knowledge base as features. An attribute vector represents each feature or a concept. ESA creates a reverse index that maps every attribute to the knowledge base concepts or the concept-attribute association vector value.</p>
                                 </td>
                              </tr>
                              <tr align="left" valign="top">
                                 <td align="left" valign="top" width="20%" id="d6547e842" headers="d6547e767 ">
                                    <p><a id="d6547e844" class="indexterm-anchor"></a><a id="d6547e846" class="indexterm-anchor"></a><span class="italic">k</span>-Means
                                    </p>
                                 </td>
                                 <td align="left" valign="top" width="18%" headers="d6547e842 d6547e770 ">
                                    <p><a id="d6547e857" class="indexterm-anchor"></a><a id="d6547e859" class="indexterm-anchor"></a>Clustering
                                    </p>
                                 </td>
                                 <td align="left" valign="top" width="62%" headers="d6547e842 d6547e773 ">
                                    <p><span class="italic">k</span>-Means is a distance-based clustering algorithm that partitions the data into a predetermined number of clusters. Each cluster has a centroid (center of gravity). Cases (individuals within the population) that are in a cluster are close to the centroid.
                                    </p>
                                    <p>Oracle Data Mining supports an enhanced version of <span class="italic">k</span>-Means. It goes beyond the classical implementation by defining <a id="d6547e874" class="indexterm-anchor"></a><a id="d6547e876" class="indexterm-anchor"></a>a hierarchical parent-child relationship of clusters.
                                    </p>
                                 </td>
                              </tr>
                              <tr align="left" valign="top">
                                 <td align="left" valign="top" width="20%" id="d6547e882" headers="d6547e767 ">
                                    <p><a id="d6547e884" class="indexterm-anchor"></a><a id="d6547e886" class="indexterm-anchor"></a>Non-Negative Matrix Factorization
                                    </p>
                                 </td>
                                 <td align="left" valign="top" width="18%" headers="d6547e882 d6547e770 ">
                                    <p><a id="d6547e893" class="indexterm-anchor"></a><a id="d6547e895" class="indexterm-anchor"></a>Feature Extraction
                                    </p>
                                 </td>
                                 <td align="left" valign="top" width="62%" headers="d6547e882 d6547e773 ">
                                    <p>Non-Negative Matrix Factorization (NMF) generates new attributes using linear combinations of the original attributes. The <a id="d6547e903" class="indexterm-anchor"></a>coefficients of the linear combinations are non-negative. During model apply, an NMF model maps the original data into the new set of attributes (features) discovered by the model.
                                    </p>
                                 </td>
                              </tr>
                              <tr align="left" valign="top">
                                 <td align="left" valign="top" width="20%" id="d6547e909" headers="d6547e767 ">
                                    <p><a id="d6547e911" class="indexterm-anchor"></a>One Class Support Vector Machines<a id="d6547e916" class="indexterm-anchor"></a></p>
                                 </td>
                                 <td align="left" valign="top" width="18%" headers="d6547e909 d6547e770 ">
                                    <p><a id="d6547e920" class="indexterm-anchor"></a><a id="d6547e922" class="indexterm-anchor"></a>Anomaly Detection
                                    </p>
                                 </td>
                                 <td align="left" valign="top" width="62%" headers="d6547e909 d6547e773 ">
                                    <p>One-class<a id="d6547e930" class="indexterm-anchor"></a> SVM builds a profile of one class. When the model is applied, it identifies cases that are somehow different from that profile. This allows for the detection of rare cases that are not necessarily related to each other.
                                    </p>
                                 </td>
                              </tr>
                              <tr align="left" valign="top">
                                 <td align="left" valign="top" width="20%" id="d6547e936" headers="d6547e767 ">
                                    <p>Orthogonal Partitioning Clustering<a id="d6547e939" class="indexterm-anchor"></a><a id="d6547e941" class="indexterm-anchor"></a></p>
                                 </td>
                                 <td align="left" valign="top" width="18%" headers="d6547e936 d6547e770 ">
                                    <p>Clustering</p>
                                 </td>
                                 <td align="left" valign="top" width="62%" headers="d6547e936 d6547e773 ">
                                    <p>Orthogonal Partitioning Clustering (o-cluster) creates a hierarchical, grid-based clustering model. The algorithm creates clusters that define dense areas in the attribute space. A sensitivity parameter defines the baseline density level. </p>
                                 </td>
                              </tr>
                              <tr align="left" valign="top">
                                 <td align="left" valign="top" width="20%" id="d6547e952" headers="d6547e767 ">
                                    <p><a id="d6547e954" class="indexterm-anchor"></a>Singular Value Decomposition and <a id="d6547e959" class="indexterm-anchor"></a><a id="d6547e961" class="indexterm-anchor"></a>Principal Component Analysis
                                    </p>
                                 </td>
                                 <td align="left" valign="top" width="18%" headers="d6547e952 d6547e770 ">
                                    <p>Feature Extraction</p>
                                 </td>
                                 <td align="left" valign="top" width="62%" headers="d6547e952 d6547e773 ">
                                    <p>Singular Value Decomposition (SVD) and Principal Component Analysis (PCA) are orthogonal linear transformations that are optimal at capturing the underlying variance of the data. This property is extremely useful for reducing the dimensionality of high-dimensional data and for supporting meaningful data visualization. </p>
                                    <p>In addition to dimensionality reduction, SVD and PCA have a number of other important applications, such as data de-noising (smoothing), data compression, matrix inversion, and solving a system of linear equations.</p>
                                 </td>
                              </tr>
                           </tbody>
                        </table>
                     </div>
                     <!-- class="inftblhruleinformal" -->
                  </div>
                  <div>
                     <div class="relinfo">
                        <p><strong>Related Topics</strong></p>
                        <ul>
                           <li><a href="algorithms-part.html#GUID-B901A29B-218C-4F37-91E0-AA94631364E3" title="Part III provides basic conceptual information about the algorithms supported by Oracle Data Mining. There is at least one algorithm for each of the mining functions.">Algorithms</a></li>
                        </ul>
                     </div>
                  </div>
               </div>
            </div><a id="DMCON625"></a><div class="props_rev_3"><a id="GUID-1F28AA79-0508-40C4-BB62-A7A7EAFE5E2F" name="GUID-1F28AA79-0508-40C4-BB62-A7A7EAFE5E2F"></a><h3 id="DMAPI-GUID-1F28AA79-0508-40C4-BB62-A7A7EAFE5E2F" class="sect3"><span class="enumeration_section">2.3 </span>Data Preparation
               </h3>
               <div>
                  <p>The quality of a model depends to a large extent on the quality of the data used to build (train) it. Much of the time spent in any given data mining project is devoted to data preparation. The data must be carefully inspected, cleansed, and transformed, and algorithm-appropriate data preparation methods must be applied.</p>
                  <p>The process of data preparation is further complicated by the fact that any data to which a model is applied, whether for testing or for scoring, must undergo the same transformations as the data used to train the model.</p>
               </div><a id="DMCON626"></a><div class="props_rev_3"><a id="GUID-C0EF2463-8975-4B15-9AC2-B64EE5C14324" name="GUID-C0EF2463-8975-4B15-9AC2-B64EE5C14324"></a><h4 id="DMAPI-GUID-C0EF2463-8975-4B15-9AC2-B64EE5C14324" class="sect4"><span class="enumeration_section">2.3.1 </span>Oracle Data Mining Simplifies Data Preparation
                  </h4>
                  <div>
                     <p>Oracle Data Mining offers several features that significantly simplify the process of data preparation: </p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p>Embedded data preparation: <a id="d6547e1036" class="indexterm-anchor"></a>The transformations used in training the model are embedded in the model and automatically executed whenever the model is applied to new data. If you specify transformations for the model, you only have to specify them once. 
                           </p>
                        </li>
                        <li>
                           <p>Automatic Data Preparation (ADP): Oracle Data Mining supports an automated data preparation mode. When ADP is active, Oracle Data Mining automatically performs the data transformations required by the algorithm. The transformation instructions are embedded in the model along with any user-specified transformation instructions.</p>
                        </li>
                        <li>
                           <p>Automatic management of missing values and sparse data: <a id="d6547e1045" class="indexterm-anchor"></a> Oracle Data Mining uses consistent methodology across mining algorithms to handle sparsity and missing values. 
                           </p>
                        </li>
                        <li>
                           <p>Transparency: Oracle Data Mining provides model details, which are a view of the attributes that are internal to the model. This insight into the inner details of the model is possible because of reverse transformations, which map the transformed attribute values to a form that can be interpreted by a user. Where possible, attribute values are reversed to the original column values. Reverse transformations are also applied to the target of a supervised model, thus the results of scoring are in the same units as the units of the original target. </p>
                        </li>
                        <li>
                           <p>Tools for custom data preparation: Oracle Data Mining provides many common transformation routines in the <code class="codeph">DBMS_DATA_MINING_TRANSFORM</code> PL/SQL package. You can use these routines, or develop your own routines in SQL, or both. The SQL language is well suited for implementing transformations in the database. You can use custom transformation instructions along with ADP or instead of ADP.
                           </p>
                        </li>
                     </ul>
                  </div>
               </div><a id="DMCON627"></a><div class="props_rev_3"><a id="GUID-FD2B3D12-42CA-4F35-AD2D-BAFD8BBE918A" name="GUID-FD2B3D12-42CA-4F35-AD2D-BAFD8BBE918A"></a><h4 id="DMAPI-GUID-FD2B3D12-42CA-4F35-AD2D-BAFD8BBE918A" class="sect4"><span class="enumeration_section">2.3.2 </span>Case Data
                  </h4>
                  <div>
                     <p>Most data mining algorithms act on single-record case data, where the information for each case is stored in a separate row. The data attributes for the cases are stored in the columns. </p>
                     <p>When the data is organized in transactions, the data for one case (one transaction) is stored in many rows. An example of transactional data is market basket data. With the single exception of Association Rules, which can operate on native transactional data, Oracle Data Mining algorithms require single-record case organization.</p>
                  </div><a id="DMCON628"></a><div class="props_rev_3"><a id="GUID-BF8E80CD-60C1-4127-95F7-C39AD83B8E63" name="GUID-BF8E80CD-60C1-4127-95F7-C39AD83B8E63"></a><h5 id="DMAPI-GUID-BF8E80CD-60C1-4127-95F7-C39AD83B8E63" class="sect5"><span class="enumeration_section">2.3.2.1 </span>Nested Data
                     </h5>
                     <div>
                        <p>Oracle Data Mining supports attributes in nested columns. A transactional table can be cast as a nested column and included in a table of single-record case data. Similarly, star schemas can be cast as nested columns. With nested data transformations, Oracle Data Mining can effectively mine data originating from multiple sources and configurations. </p>
                     </div>
                  </div>
               </div><a id="DMCON638"></a><div class="props_rev_3"><a id="GUID-32CBE82E-326F-4BCF-B45D-26E3F1660191" name="GUID-32CBE82E-326F-4BCF-B45D-26E3F1660191"></a><h4 id="DMAPI-GUID-32CBE82E-326F-4BCF-B45D-26E3F1660191" class="sect4"><span class="enumeration_section">2.3.3 </span>Text Data
                  </h4>
                  <div>
                     <p>Prepare and transform unstructured text data for data mining.</p>
                     <p><a id="d6547e1121" class="indexterm-anchor"></a><a id="d6547e1123" class="indexterm-anchor"></a>Oracle Data Mining interprets <code class="codeph">CLOB</code> columns and long <code class="codeph">VARCHAR2</code> columns automatically as unstructured text. Additionally, you can specify columns of short <code class="codeph">VARCHAR2</code>, <code class="codeph">CHAR</code>, <code class="codeph">BLOB</code>, and <code class="codeph">BFILE</code> as unstructured text. Unstructured text includes data items such as web pages, document libraries, Power Point presentations, product specifications, emails, comment fields in reports, and call center notes. 
                     </p>
                     <p>Oracle Data Mining uses Oracle Text utilities and term weighting strategies to transform unstructured text for mining. In text transformation, text terms are extracted and given numeric values in a text index. The text transformation process is configurable for the model and for individual attributes. Once transformed, the text can by mined with a data mining algorithm. </p>
                  </div>
                  <div>
                     <div class="relinfo">
                        <p><strong>Related Topics</strong></p>
                        <ul>
                           <li><a href="../dmprg/preparing-data.html#DMPRG-GUID-E1AB599C-1921-4BD7-B06B-FC466180A460">Preparing the Data</a></li>
                           <li><a href="../dmprg/transforming-data.html#DMPRG-GUID-C3FDDEC7-8CC9-4AC1-A6C3-75D91E26B703">Transforming the Data</a></li>
                           <li><a href="../dmprg/mining-unstructured-text.html#DMPRG-GUID-DC9371F7-B16A-43C7-A563-5C2016064E72">Mining Unstructured Text</a></li>
                        </ul>
                     </div>
                  </div>
               </div>
            </div><a id="DMCON630"></a><div class="props_rev_3"><a id="GUID-21677973-2248-4119-A560-24D7F2FD7EAD" name="GUID-21677973-2248-4119-A560-24D7F2FD7EAD"></a><h3 id="DMAPI-GUID-21677973-2248-4119-A560-24D7F2FD7EAD" class="sect3"><span class="enumeration_section">2.4 </span>In-Database Scoring
               </h3>
               <div>
                  <p>Scoring is the application of a data mining algorithm to new data. In traditional data mining, models are built using specialized software on a remote system and deployed to another system for scoring. This is a cumbersome, error-prone process open to security violations and difficulties in data synchronization.</p>
                  <p>With Oracle Data Mining, scoring is easy and secure. The scoring engine and the data both reside within the database. Scoring is an extension to the SQL language, so the results of mining can easily be incorporated into applications and reporting systems.</p>
               </div><a id="DMCON668"></a><div class="props_rev_3"><a id="GUID-6BFCB980-D04A-42B6-A3BD-74FCF352A500" name="GUID-6BFCB980-D04A-42B6-A3BD-74FCF352A500"></a><h4 id="DMAPI-GUID-6BFCB980-D04A-42B6-A3BD-74FCF352A500" class="sect4"><span class="enumeration_section">2.4.1 </span>Parallel Execution and Ease of Administration
                  </h4>
                  <div>
                     <p>All Oracle Data Mining scoring routines support parallel execution for scoring large data sets.</p>
                     <p>In-database <a id="d6547e1204" class="indexterm-anchor"></a>scoring provides performance advantages. All Oracle Data Mining scoring routines support <a id="d6547e1209" class="indexterm-anchor"></a>parallel execution, which significantly reduces the time required for executing complex queries and scoring large data sets. 
                     </p>
                     <p>In-database mining minimizes the IT effort needed to support data mining initiatives. Using standard database techniques, models can easily be refreshed (re-created) on more recent data and redeployed. The deployment is immediate since the scoring query remains the same; only the underlying model is replaced in the database.</p>
                  </div>
                  <div>
                     <div class="relinfo">
                        <p><strong>Related Topics</strong></p>
                        <ul>
                           <li><a href="../vldbg/using-parallel.html#VLDBG010"><span><cite>Oracle Database VLDB and Partitioning Guide</cite></span></a></li>
                        </ul>
                     </div>
                  </div>
               </div><a id="DMCON631"></a><a id="DMCON632"></a><a id="DMCON669"></a><div class="props_rev_3"><a id="GUID-B4916CE4-F771-4111-A5DF-20977FB3EE49" name="GUID-B4916CE4-F771-4111-A5DF-20977FB3EE49"></a><h4 id="DMAPI-GUID-B4916CE4-F771-4111-A5DF-20977FB3EE49" class="sect4"><span class="enumeration_section">2.4.2 </span>SQL Functions for Model Apply and Dynamic Scoring
                  </h4>
                  <div>
                     <p>In Oracle Data Mining, scoring is performed by SQL language functions. Understand the different ways involved in SQL function scoring.</p>
                     <p><a id="d6547e1244" class="indexterm-anchor"></a>The functions perform prediction, clustering, and feature extraction. The functions can be invoked in two different ways: By applying a mining model object (<a href="oracle-data-mining-basics.html#GUID-B4916CE4-F771-4111-A5DF-20977FB3EE49__BABDDAEF">Example 2-1</a>), or by executing an analytic clause that computes the mining analysis dynamically and applies it to the data (<a href="oracle-data-mining-basics.html#GUID-B4916CE4-F771-4111-A5DF-20977FB3EE49__BABGEAJA">Example 2-2</a>). Dynamic scoring, which eliminates the need for a model, can supplement, or even replace, the more traditional data mining methodology described in <span class="q">"The Data Mining Process"</span>.
                     </p>
                     <p>In <a href="oracle-data-mining-basics.html#GUID-B4916CE4-F771-4111-A5DF-20977FB3EE49__BABDDAEF">Example 2-1</a>, the <code class="codeph">PREDICTION_PROBABILITY</code> function applies the model svmc_sh_clas_sample, created in <a href="introduction-to-oracle-data-mining.html#GUID-EC7AC64D-CFB7-48CE-9B54-9E553DD79234__BABEHGJB">Example 1-1</a>, to score the data in <code class="codeph">mining_data_apply_v</code>. The function returns the ten customers in Italy who are most likely to use an affinity card.
                     </p>
                     <p>In <a href="oracle-data-mining-basics.html#GUID-B4916CE4-F771-4111-A5DF-20977FB3EE49__BABGEAJA">Example 2-2</a>, the functions <code class="codeph">PREDICTION</code> and <code class="codeph">PREDICTION_PROBABILITY</code> use the analytic syntax (the <code class="codeph">OVER</code> () clause) to dynamically score the data in <code class="codeph">mining_data_apply_v</code>. The query returns the customers who currently do not have an affinity card with the probability that they are likely to use.
                     </p>
                     <div class="example" id="GUID-B4916CE4-F771-4111-A5DF-20977FB3EE49__BABDDAEF">
                        <p class="titleinexample">Example 2-1 Applying a Mining Model to Score Data</p><pre class="oac_no_warn" dir="ltr">SELECT cust_id FROM
  (SELECT cust_id, 
        rank() over (order by PREDICTION_PROBABILITY(svmc_sh_clas_sample, 1
                     USING *) DESC, cust_id) rnk
   FROM mining_data_apply_v
   WHERE country_name = 'Italy')
WHERE rnk &lt;= 10
ORDER BY rnk;

   CUST_ID
----------
    101445
    100179
    100662
    100733
    100554
    100081
    100344
    100324
    100185
    101345
</pre></div>
                     <!-- class="example" -->
                     <div class="example" id="GUID-B4916CE4-F771-4111-A5DF-20977FB3EE49__BABGEAJA">
                        <p class="titleinexample">Example 2-2 Executing an Analytic Function to Score Data</p><pre class="oac_no_warn" dir="ltr">SELECT cust_id, pred_prob FROM
  (SELECT cust_id, affinity_card, 
    PREDICTION(FOR TO_CHAR(affinity_card) USING *) OVER () pred_card,
    PREDICTION_PROBABILITY(FOR TO_CHAR(affinity_card),1 USING *) OVER () pred_prob
   FROM mining_data_build_v)
WHERE affinity_card = 0
AND pred_card = 1
ORDER BY pred_prob DESC;

   CUST_ID PRED_PROB
---------- ---------
    102434       .96
    102365       .96
    102330       .96
    101733       .95
    102615       .94
    102686       .94
    102749       .93
    .
    .
    .
    101656       .51</pre></div>
                     <!-- class="example" -->
                  </div>
               </div>
            </div>
         </div>
      </article>
   </body>
</html>